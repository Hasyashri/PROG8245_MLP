{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9c231a0",
   "metadata": {},
   "source": [
    "># Lab -3 Data Engineering & Exploratory Data Analysis (EDA) Workshop\n",
    "\n",
    "**Student Name:** `Hasyashri Bhatt`\n",
    "\n",
    "**Student Number:**`9028501`\n",
    "\n",
    "**Course:**`Machine Learning Programming(PROG8245)`\n",
    "\n",
    "**Reference:** For the coding understanding and reference I used chatgpt,copilot and W3School.com\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a80a82",
   "metadata": {},
   "source": [
    "**Introduction:**\n",
    "\n",
    "This lab focuses on practical data engineering and exploratory data analysis (EDA) using Python, SQL, and cloud-based infrastructure. We connect to a PostgreSQL database hosted on Neon.tech, populate it with synthetic employee data, and then perform a series of data processing and analytical tasks using the Pandas library. The aim is to simulate a real-world scenario where data must be collected, cleaned, transformed, and visualized to extract meaningful business insights.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7027a189",
   "metadata": {},
   "source": [
    "**Objective:**\n",
    "\n",
    "1.Set up a free PostgreSQL cloud database on Neon.tech\n",
    "\n",
    "2.Generate and insert synthetic employee data using the Faker library\n",
    "\n",
    "3.Connect to the database with Psycopg2 and SQLAlchemy\n",
    "\n",
    "4.Load data into a Pandas DataFrame and perform:\n",
    "\n",
    "         - Data cleaning and transformation\n",
    "\n",
    "         - Feature engineering (e.g., calculating years of service)\n",
    "\n",
    "         - Scaling numeric data\n",
    "\n",
    "5.Create and interpret two visualizations:\n",
    "\n",
    "         - A grouped bar chart (salary by position and start year)\n",
    "\n",
    "         - An advanced heatmap using joined department data\n",
    "\n",
    "---         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2079e2c",
   "metadata": {},
   "source": [
    "\n",
    "> ## **1. Data Collection**\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cfbe83",
   "metadata": {},
   "source": [
    "I created a free cloud database using `Neon.tech`, a service that provides a PostgreSQL database without needing a credit card.In the database, we created a table named employees. It contains the following information:\n",
    "\n",
    "`employee_id:` A unique ID for each employee\n",
    "\n",
    "`name:` The employee's full name\n",
    "\n",
    "`position:` Their job title (all in IT field)\n",
    "\n",
    "`start_date:` The year they joined the company (between 2015â€“2024)\n",
    "\n",
    "`salary:` Their annual salary (ranging from $60,000 to $200,000)\n",
    "\n",
    " I used a library called psycopg2 to connect Python to the cloud database and Pandas to bring the data into a format we can analyze.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f630ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import random\n",
    "import pandas as pd\n",
    "from faker import Faker\n",
    "from datetime import date # Import the date object\n",
    "import psycopg2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f2d097",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**After this,I used a Python library called Faker to create 50 fake (but realistic) employee records. These records were then inserted into the cloud database manually copy and pasting in the SQL editor to create Employee table with 50 fake data.**\n",
    "\n",
    "`Note:` Below data changes everytime when we run the code but When I run this for the first time I copy-pasted that data in the Cloud database called `Neon.tech`,So my all result will include that database entries not the current one.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36f8489c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Jessica Black', 'DevOps Engineer', '2016-08-17', 102297);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Justin Powell', 'Data Scientist', '2022-04-18', 156464);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Michael Palmer', 'ML Engineer', '2019-01-07', 112727);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Shannon Thompson', 'SysAdmin', '2023-10-15', 109305);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('James Foster', 'Data Scientist', '2018-08-10', 104833);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Jessica Smith', 'DevOps Engineer', '2015-08-27', 64791);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Ashley Ashley', 'Cloud Architect', '2019-10-07', 184471);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Rachel Perry', 'Backend Developer', '2022-09-30', 192468);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Bryan Nelson', 'Data Analyst', '2022-07-02', 190526);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Amanda Craig', 'QA Engineer', '2016-01-19', 175693);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Cynthia Taylor', 'Data Analyst', '2016-11-04', 111739);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Gerald Warner', 'Data Analyst', '2015-07-01', 120018);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Jesus Butler', 'ML Engineer', '2022-06-29', 89821);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Lindsay Boyle', 'Software Engineer', '2019-07-12', 105489);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Richard Turner', 'Data Scientist', '2018-03-05', 153069);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Jennifer Mcbride', 'SysAdmin', '2023-07-16', 171505);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Danny Dawson', 'Software Engineer', '2020-10-29', 77652);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Timothy Cook', 'ML Engineer', '2020-01-21', 79816);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Joseph Ali', 'ML Engineer', '2017-11-25', 143631);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Monica Golden', 'Data Analyst', '2015-10-17', 120028);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Robert Miller', 'Cloud Architect', '2020-09-18', 121734);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Jennifer Benson', 'Backend Developer', '2015-08-03', 187223);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Mary West', 'Backend Developer', '2020-04-05', 105014);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Barbara Gardner', 'Backend Developer', '2022-06-11', 104829);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Gregory Harris', 'Software Engineer', '2018-05-31', 84231);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Logan Silva', 'DevOps Engineer', '2019-03-14', 178484);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Rebecca Carter', 'QA Engineer', '2021-08-08', 63200);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('April Villegas', 'DevOps Engineer', '2018-07-27', 176544);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Meredith Jackson', 'Frontend Developer', '2017-02-17', 140904);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Carol Mendez', 'DevOps Engineer', '2017-05-28', 180020);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Lisa King', 'Backend Developer', '2017-10-06', 153971);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Kimberly Alexander', 'Data Analyst', '2023-07-28', 67208);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Kristopher Lin', 'Frontend Developer', '2021-10-06', 95598);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Carmen Shaw', 'SysAdmin', '2022-02-13', 77913);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Kathy Moore', 'Data Scientist', '2019-09-16', 88923);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Shawn Moore', 'Data Analyst', '2021-06-27', 115207);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Kayla Barber', 'Data Scientist', '2020-06-06', 92836);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Stephen Price', 'ML Engineer', '2020-06-30', 161679);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Jennifer Jackson', 'Frontend Developer', '2021-07-17', 124194);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Eddie Liu', 'Cloud Architect', '2020-06-01', 160359);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Carrie Johnson', 'SysAdmin', '2018-08-02', 196824);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Tami Stanley', 'Data Scientist', '2019-05-25', 159154);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Beth Harris', 'Data Analyst', '2018-12-21', 173767);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Zachary Mcneil', 'QA Engineer', '2020-01-17', 143200);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Carrie Robinson', 'Software Engineer', '2023-10-18', 118432);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Alex Padilla', 'DevOps Engineer', '2019-11-19', 107660);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Natalie Casey', 'Data Analyst', '2023-06-25', 159420);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Erin Evans', 'Cloud Architect', '2018-07-28', 73044);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Vanessa Ayala', 'SysAdmin', '2019-07-19', 127219);\n",
      "INSERT INTO employees (name, position, start_date, salary) VALUES ('Joshua Carlson', 'Data Scientist', '2017-02-23', 70261);\n"
     ]
    }
   ],
   "source": [
    "fake = Faker()\n",
    "\n",
    "positions = [\n",
    "    'Software Engineer', 'Data Analyst', 'DevOps Engineer', 'ML Engineer', 'QA Engineer',\n",
    "    'Backend Developer', 'Frontend Developer', 'Cloud Architect', 'SysAdmin', 'Data Scientist'\n",
    "]\n",
    "\n",
    "# Convert date strings to date objects\n",
    "start_date_obj = date(2015, 1, 1)\n",
    "end_date_obj = date(2024, 6, 1)\n",
    "\n",
    "for i in range(50):\n",
    "    name = fake.name().replace(\"'\", \"''\")  # Escape single quotes in names\n",
    "    position = random.choice(positions)\n",
    "    #Pass date objects to date_between\n",
    "    start_date = fake.date_between(start_date=start_date_obj, end_date=end_date_obj)\n",
    "    salary = random.randint(60000, 200000)\n",
    "\n",
    "    print(f\"INSERT INTO employees (name, position, start_date, salary) VALUES ('{name}', '{position}', '{start_date}', {salary});\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb22021b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "In below step I made bridge between python and Cloud Database Neon.tech using a link from the cloud    \n",
    "database. After that, I established connection using `conn`. \n",
    "\n",
    "I have data into the Database in the Employee table, to process with the dataset into notebook we need to Load and save this database in the dataframe using `df`.\n",
    "\n",
    "I used `.head()` method to see the first five row of the Employee Database which I saved in df variable.\n",
    "\n",
    "In last, I closed the connection using `.close()` method.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b17a6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining connection string from Neon.tech\n",
    "conn_str= \"postgresql://neondb_owner:npg_dAGu8XqN7cBz@ep-black-recipe-a8in5l8k-pooler.eastus2.azure.neon.tech/neondb?sslmode=require\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "191a0cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established successfully\n"
     ]
    }
   ],
   "source": [
    "# Connect to the database\n",
    "conn = psycopg2.connect(conn_str)\n",
    "\n",
    "print(\"Connection established successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "00db776c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\habha\\AppData\\Local\\Temp\\ipykernel_24720\\4213409181.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(\"SELECT * FROM employees;\", conn)\n"
     ]
    }
   ],
   "source": [
    "# Query the table and load into Pandas\n",
    "df = pd.read_sql_query(\"SELECT * FROM employees;\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31e06e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "employee_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "position",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "start_date",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "salary",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "5d108fa5-942f-4add-bedc-8bfe9b6a56a0",
       "rows": [
        [
         "0",
         "1",
         "Dustin Martin",
         "QA Engineer",
         "2022-07-04",
         "177459"
        ],
        [
         "1",
         "2",
         "John Ward",
         "SysAdmin",
         "2017-03-29",
         "178790"
        ],
        [
         "2",
         "3",
         "Benjamin Ramirez",
         "ML Engineer",
         "2018-08-11",
         "120220"
        ],
        [
         "3",
         "4",
         "Karl Johnson",
         "QA Engineer",
         "2019-02-28",
         "169171"
        ],
        [
         "4",
         "5",
         "Tiffany Weaver",
         "DevOps Engineer",
         "2017-08-07",
         "103453"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>name</th>\n",
       "      <th>position</th>\n",
       "      <th>start_date</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Dustin Martin</td>\n",
       "      <td>QA Engineer</td>\n",
       "      <td>2022-07-04</td>\n",
       "      <td>177459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>John Ward</td>\n",
       "      <td>SysAdmin</td>\n",
       "      <td>2017-03-29</td>\n",
       "      <td>178790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Benjamin Ramirez</td>\n",
       "      <td>ML Engineer</td>\n",
       "      <td>2018-08-11</td>\n",
       "      <td>120220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Karl Johnson</td>\n",
       "      <td>QA Engineer</td>\n",
       "      <td>2019-02-28</td>\n",
       "      <td>169171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Tiffany Weaver</td>\n",
       "      <td>DevOps Engineer</td>\n",
       "      <td>2017-08-07</td>\n",
       "      <td>103453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_id              name         position  start_date  salary\n",
       "0            1     Dustin Martin      QA Engineer  2022-07-04  177459\n",
       "1            2         John Ward         SysAdmin  2017-03-29  178790\n",
       "2            3  Benjamin Ramirez      ML Engineer  2018-08-11  120220\n",
       "3            4      Karl Johnson      QA Engineer  2019-02-28  169171\n",
       "4            5    Tiffany Weaver  DevOps Engineer  2017-08-07  103453"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the first 5 rows of the DataFrame Which is saved in df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91db73b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d7a476",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> ## **2. Data Cleaning**\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c5dff4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "After collecting the data, I checked for any missing or incorrect values using:\n",
    "\n",
    "`.info()`â€” to understand the data types and spot any null entries \n",
    "\n",
    "`.isnull().sum()` â€” to count missing values in each column\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eabd7aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   employee_id  50 non-null     int64 \n",
      " 1   name         50 non-null     object\n",
      " 2   position     50 non-null     object\n",
      " 3   start_date   50 non-null     object\n",
      " 4   salary       50 non-null     int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Display DataFrame information\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b61c4be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "724857bc-fc20-4cee-a0a3-b43d299b1c10",
       "rows": [
        [
         "employee_id",
         "0"
        ],
        [
         "name",
         "0"
        ],
        [
         "position",
         "0"
        ],
        [
         "start_date",
         "0"
        ],
        [
         "salary",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 5
       }
      },
      "text/plain": [
       "employee_id    0\n",
       "name           0\n",
       "position       0\n",
       "start_date     0\n",
       "salary         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4a43f1de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "df.duplicated().sum()  # Count the number of duplicate rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4993b2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "I ensured that all data is complete and consistent. Here,`start_date` has object datatype which should be time and date format.I also checked if any duplicate data is present in the database using `.duplicated()` There are no missing values found. I would have fixed or removed them â€” but in this case, the generated data was clean.\n",
    "\n",
    "In below step, I have converted object datatype to Date and time datatype for `start_date` \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "169d51da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "start_date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        }
       ],
       "ref": "21f10d89-b1a0-481d-ade6-478a6f768c10",
       "rows": [
        [
         "0",
         "2022-07-04 00:00:00"
        ],
        [
         "1",
         "2017-03-29 00:00:00"
        ],
        [
         "2",
         "2018-08-11 00:00:00"
        ],
        [
         "3",
         "2019-02-28 00:00:00"
        ],
        [
         "4",
         "2017-08-07 00:00:00"
        ],
        [
         "5",
         "2019-08-29 00:00:00"
        ],
        [
         "6",
         "2019-05-22 00:00:00"
        ],
        [
         "7",
         "2017-11-10 00:00:00"
        ],
        [
         "8",
         "2017-02-06 00:00:00"
        ],
        [
         "9",
         "2020-05-14 00:00:00"
        ],
        [
         "10",
         "2018-07-17 00:00:00"
        ],
        [
         "11",
         "2021-01-04 00:00:00"
        ],
        [
         "12",
         "2015-03-27 00:00:00"
        ],
        [
         "13",
         "2016-11-23 00:00:00"
        ],
        [
         "14",
         "2020-08-22 00:00:00"
        ],
        [
         "15",
         "2017-03-22 00:00:00"
        ],
        [
         "16",
         "2018-02-01 00:00:00"
        ],
        [
         "17",
         "2021-12-03 00:00:00"
        ],
        [
         "18",
         "2016-05-14 00:00:00"
        ],
        [
         "19",
         "2022-12-28 00:00:00"
        ],
        [
         "20",
         "2017-07-02 00:00:00"
        ],
        [
         "21",
         "2018-04-30 00:00:00"
        ],
        [
         "22",
         "2020-04-07 00:00:00"
        ],
        [
         "23",
         "2015-12-16 00:00:00"
        ],
        [
         "24",
         "2015-03-02 00:00:00"
        ],
        [
         "25",
         "2019-01-03 00:00:00"
        ],
        [
         "26",
         "2021-05-28 00:00:00"
        ],
        [
         "27",
         "2023-04-24 00:00:00"
        ],
        [
         "28",
         "2016-02-18 00:00:00"
        ],
        [
         "29",
         "2016-11-23 00:00:00"
        ],
        [
         "30",
         "2015-08-26 00:00:00"
        ],
        [
         "31",
         "2020-02-24 00:00:00"
        ],
        [
         "32",
         "2015-11-24 00:00:00"
        ],
        [
         "33",
         "2023-10-20 00:00:00"
        ],
        [
         "34",
         "2018-12-21 00:00:00"
        ],
        [
         "35",
         "2018-03-09 00:00:00"
        ],
        [
         "36",
         "2018-10-14 00:00:00"
        ],
        [
         "37",
         "2023-08-29 00:00:00"
        ],
        [
         "38",
         "2015-05-22 00:00:00"
        ],
        [
         "39",
         "2020-06-11 00:00:00"
        ],
        [
         "40",
         "2015-08-20 00:00:00"
        ],
        [
         "41",
         "2015-12-20 00:00:00"
        ],
        [
         "42",
         "2015-12-17 00:00:00"
        ],
        [
         "43",
         "2022-04-16 00:00:00"
        ],
        [
         "44",
         "2021-02-01 00:00:00"
        ],
        [
         "45",
         "2024-01-15 00:00:00"
        ],
        [
         "46",
         "2023-12-22 00:00:00"
        ],
        [
         "47",
         "2020-01-08 00:00:00"
        ],
        [
         "48",
         "2021-03-19 00:00:00"
        ],
        [
         "49",
         "2020-06-12 00:00:00"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 50
       }
      },
      "text/plain": [
       "0    2022-07-04\n",
       "1    2017-03-29\n",
       "2    2018-08-11\n",
       "3    2019-02-28\n",
       "4    2017-08-07\n",
       "5    2019-08-29\n",
       "6    2019-05-22\n",
       "7    2017-11-10\n",
       "8    2017-02-06\n",
       "9    2020-05-14\n",
       "10   2018-07-17\n",
       "11   2021-01-04\n",
       "12   2015-03-27\n",
       "13   2016-11-23\n",
       "14   2020-08-22\n",
       "15   2017-03-22\n",
       "16   2018-02-01\n",
       "17   2021-12-03\n",
       "18   2016-05-14\n",
       "19   2022-12-28\n",
       "20   2017-07-02\n",
       "21   2018-04-30\n",
       "22   2020-04-07\n",
       "23   2015-12-16\n",
       "24   2015-03-02\n",
       "25   2019-01-03\n",
       "26   2021-05-28\n",
       "27   2023-04-24\n",
       "28   2016-02-18\n",
       "29   2016-11-23\n",
       "30   2015-08-26\n",
       "31   2020-02-24\n",
       "32   2015-11-24\n",
       "33   2023-10-20\n",
       "34   2018-12-21\n",
       "35   2018-03-09\n",
       "36   2018-10-14\n",
       "37   2023-08-29\n",
       "38   2015-05-22\n",
       "39   2020-06-11\n",
       "40   2015-08-20\n",
       "41   2015-12-20\n",
       "42   2015-12-17\n",
       "43   2022-04-16\n",
       "44   2021-02-01\n",
       "45   2024-01-15\n",
       "46   2023-12-22\n",
       "47   2020-01-08\n",
       "48   2021-03-19\n",
       "49   2020-06-12\n",
       "Name: start_date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data cleaning steps\n",
    "# Convert to datetime\n",
    "df['start_date'] = pd.to_datetime(df['start_date'], errors='coerce') \n",
    "df['start_date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac651e6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> ## **3. Data Transformation & Feature Engineering**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "193b4474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['employee_id', 'name', 'position', 'start_date', 'salary'], dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of all column name using .columns Before creating the new column \n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9b8186",
   "metadata": {},
   "source": [
    "I added a new column called years_of_service, which shows how many years an employee has worked in the company.\n",
    "\n",
    "This was calculated by subtracting the employeeâ€™s start year from the current year.\n",
    "\n",
    "I converted all job position titles to lowercase letters. This ensures consistency in the data. For example, \"Data Engineer\", \"data engineer\", and \"DATA ENGINEER\" are now all treated as the same role: `\"data engineer\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3a7081d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "position",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "c4646f17-8c30-4ac9-8a61-424139c4b302",
       "rows": [
        [
         "0",
         "qa engineer"
        ],
        [
         "1",
         "sysadmin"
        ],
        [
         "2",
         "ml engineer"
        ],
        [
         "3",
         "qa engineer"
        ],
        [
         "4",
         "devops engineer"
        ],
        [
         "5",
         "devops engineer"
        ],
        [
         "6",
         "software engineer"
        ],
        [
         "7",
         "data analyst"
        ],
        [
         "8",
         "devops engineer"
        ],
        [
         "9",
         "data analyst"
        ],
        [
         "10",
         "software engineer"
        ],
        [
         "11",
         "data scientist"
        ],
        [
         "12",
         "data scientist"
        ],
        [
         "13",
         "data analyst"
        ],
        [
         "14",
         "qa engineer"
        ],
        [
         "15",
         "ml engineer"
        ],
        [
         "16",
         "data analyst"
        ],
        [
         "17",
         "cloud architect"
        ],
        [
         "18",
         "backend developer"
        ],
        [
         "19",
         "backend developer"
        ],
        [
         "20",
         "devops engineer"
        ],
        [
         "21",
         "frontend developer"
        ],
        [
         "22",
         "software engineer"
        ],
        [
         "23",
         "software engineer"
        ],
        [
         "24",
         "cloud architect"
        ],
        [
         "25",
         "cloud architect"
        ],
        [
         "26",
         "cloud architect"
        ],
        [
         "27",
         "sysadmin"
        ],
        [
         "28",
         "sysadmin"
        ],
        [
         "29",
         "data scientist"
        ],
        [
         "30",
         "sysadmin"
        ],
        [
         "31",
         "sysadmin"
        ],
        [
         "32",
         "data scientist"
        ],
        [
         "33",
         "cloud architect"
        ],
        [
         "34",
         "devops engineer"
        ],
        [
         "35",
         "software engineer"
        ],
        [
         "36",
         "data scientist"
        ],
        [
         "37",
         "sysadmin"
        ],
        [
         "38",
         "cloud architect"
        ],
        [
         "39",
         "ml engineer"
        ],
        [
         "40",
         "ml engineer"
        ],
        [
         "41",
         "cloud architect"
        ],
        [
         "42",
         "qa engineer"
        ],
        [
         "43",
         "backend developer"
        ],
        [
         "44",
         "software engineer"
        ],
        [
         "45",
         "devops engineer"
        ],
        [
         "46",
         "sysadmin"
        ],
        [
         "47",
         "backend developer"
        ],
        [
         "48",
         "software engineer"
        ],
        [
         "49",
         "backend developer"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 50
       }
      },
      "text/plain": [
       "0            qa engineer\n",
       "1               sysadmin\n",
       "2            ml engineer\n",
       "3            qa engineer\n",
       "4        devops engineer\n",
       "5        devops engineer\n",
       "6      software engineer\n",
       "7           data analyst\n",
       "8        devops engineer\n",
       "9           data analyst\n",
       "10     software engineer\n",
       "11        data scientist\n",
       "12        data scientist\n",
       "13          data analyst\n",
       "14           qa engineer\n",
       "15           ml engineer\n",
       "16          data analyst\n",
       "17       cloud architect\n",
       "18     backend developer\n",
       "19     backend developer\n",
       "20       devops engineer\n",
       "21    frontend developer\n",
       "22     software engineer\n",
       "23     software engineer\n",
       "24       cloud architect\n",
       "25       cloud architect\n",
       "26       cloud architect\n",
       "27              sysadmin\n",
       "28              sysadmin\n",
       "29        data scientist\n",
       "30              sysadmin\n",
       "31              sysadmin\n",
       "32        data scientist\n",
       "33       cloud architect\n",
       "34       devops engineer\n",
       "35     software engineer\n",
       "36        data scientist\n",
       "37              sysadmin\n",
       "38       cloud architect\n",
       "39           ml engineer\n",
       "40           ml engineer\n",
       "41       cloud architect\n",
       "42           qa engineer\n",
       "43     backend developer\n",
       "44     software engineer\n",
       "45       devops engineer\n",
       "46              sysadmin\n",
       "47     backend developer\n",
       "48     software engineer\n",
       "49     backend developer\n",
       "Name: position, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert all position titles to lowercase\n",
    "df['position'] = df['position'].str.lower()\n",
    "df['position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "37d6d562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# handle missing data (e.g., fill with a value)\n",
    "df['salary'].fillna(0)\n",
    "# Check if there are still any missing values in the 'salary' column\n",
    "df['salary'].isnull().sum()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d97e52bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "years_service",
         "rawType": "int32",
         "type": "integer"
        }
       ],
       "ref": "afa7617f-a9bd-4cf3-96da-fc6ed31cf579",
       "rows": [
        [
         "0",
         "3"
        ],
        [
         "1",
         "8"
        ],
        [
         "2",
         "7"
        ],
        [
         "3",
         "6"
        ],
        [
         "4",
         "8"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 5
       }
      },
      "text/plain": [
       "0    3\n",
       "1    8\n",
       "2    7\n",
       "3    6\n",
       "4    8\n",
       "Name: years_service, dtype: int32"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# created a new column (years of service) from the start_date column extracting the year and subtracting it from the current year\n",
    "from datetime import date\n",
    "df['years_service'] = date.today().year - pd.DatetimeIndex(df['start_date']).year\n",
    "df['years_service'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c812b55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "start_year",
         "rawType": "int32",
         "type": "integer"
        }
       ],
       "ref": "955cbb1e-359a-4148-baa1-a01c302410de",
       "rows": [
        [
         "0",
         "2022"
        ],
        [
         "1",
         "2017"
        ],
        [
         "2",
         "2018"
        ],
        [
         "3",
         "2019"
        ],
        [
         "4",
         "2017"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 5
       }
      },
      "text/plain": [
       "0    2022\n",
       "1    2017\n",
       "2    2018\n",
       "3    2019\n",
       "4    2017\n",
       "Name: start_year, dtype: int32"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Start Year column\n",
    "df['start_year'] = df['start_date'].dt.year\n",
    "df['start_year'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ecff7e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['employee_id', 'name', 'position', 'start_date', 'salary',\n",
       "       'years_service', 'start_year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show new column names using .columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecc1109",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
